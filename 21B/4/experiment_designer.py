#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®éªŒè®¾è®¡ä¸»ç¨‹åº - GPRå®éªŒè®¾è®¡ç³»ç»Ÿ
åŠŸèƒ½ï¼šæ•´åˆæ‰€æœ‰æ¨¡å—ï¼Œå®ŒæˆåŸºäºGPR+EIçš„å®éªŒè®¾è®¡
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, List, Tuple
import warnings
warnings.filterwarnings('ignore')

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from data_processor import DataProcessor
from gpr_model import GPRModel
from candidate_generator import CandidateGenerator
from ei_optimizer import EIOptimizer

# è®¾ç½®ä¸­æ–‡å­—ä½“
import platform
if platform.system() == 'Darwin':  # macOS
    plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']
elif platform.system() == 'Windows':
    plt.rcParams['font.sans-serif'] = ['SimHei'] # Windows
else:  # Linux
    plt.rcParams['font.sans-serif'] = ['WenQuanYi Micro Hei'] # Linux
plt.rcParams['axes.unicode_minus'] = False

class ExperimentDesigner:
    """å®éªŒè®¾è®¡å™¨ä¸»ç±»"""
    
    def __init__(self, random_state: int = 42):
        """åˆå§‹åŒ–å®éªŒè®¾è®¡å™¨"""
        self.random_state = random_state
        np.random.seed(random_state)
        
        # åˆå§‹åŒ–å„æ¨¡å—
        self.data_processor = DataProcessor()
        self.gpr_model = GPRModel(random_state=random_state)
        self.candidate_generator = CandidateGenerator(random_state=random_state)
        self.ei_optimizer = EIOptimizer(xi=0.01)
        
        # å­˜å‚¨ä¸­é—´ç»“æœ
        self.X_train = None
        self.y_train = None
        self.scaler = None
        self.variable_bounds = None
        self.candidates_scaled = None
        self.candidates_original = None
        self.gpr_fitted = None
        self.y_best = None
        
    def load_and_process_data(self, data_path: str = "é™„ä»¶1.csv", 
                            catalyst_path: str = "æ¯ç»„æŒ‡æ ‡.csv") -> Tuple[np.ndarray, np.ndarray]:
        """
        åŠ è½½å’Œå¤„ç†æ•°æ®
        
        Args:
            data_path: ä¸»æ•°æ®æ–‡ä»¶è·¯å¾„
            catalyst_path: å‚¬åŒ–å‰‚æ•°æ®æ–‡ä»¶è·¯å¾„
            
        Returns:
            X_train: è®­ç»ƒç‰¹å¾çŸ©é˜µ
            y_train: è®­ç»ƒç›®æ ‡å‘é‡
        """
        print("ğŸ”„ æ­¥éª¤1: æ•°æ®åŠ è½½ä¸é¢„å¤„ç†...")
        
        # åŠ è½½å’Œé¢„å¤„ç†æ•°æ®
        self.X_train, self.y_train, data_info = self.data_processor.load_and_prepare_data(data_path, catalyst_path)
        
        # è·å–æ ‡å‡†åŒ–å™¨
        self.scaler = self.data_processor.scaler
        
        # è·å–å˜é‡è¾¹ç•Œ
        self.variable_bounds = self.data_processor.get_variable_bounds()
        
        # è®°å½•å½“å‰æœ€ä½³æ”¶ç‡
        self.y_best = np.max(self.y_train)
        
        print(f"âœ… æ•°æ®å¤„ç†å®Œæˆ!")
        print(f"   ğŸ“Š è®­ç»ƒæ ·æœ¬æ•°: {len(self.X_train)}")
        print(f"   ğŸ“‹ ç‰¹å¾ç»´åº¦: {self.X_train.shape[1]}")
        print(f"   ğŸ¯ å½“å‰æœ€ä½³æ”¶ç‡: {self.y_best:.4f}")
        
        return self.X_train, self.y_train
    
    def build_gpr_model(self) -> None:
        """æ„å»ºå’Œè®­ç»ƒGPRæ¨¡å‹"""
        print("\nğŸ”„ æ­¥éª¤2: GPRæ¨¡å‹æ„å»ºä¸è®­ç»ƒ...")
        
        # è®­ç»ƒæ¨¡å‹
        training_results = self.gpr_model.build_and_train(self.X_train, self.y_train)
        self.gpr_fitted = self.gpr_model
        
        # è·å–éªŒè¯ç»“æœ
        validation_results = training_results['validation_results']
        
        print(f"âœ… GPRæ¨¡å‹è®­ç»ƒå®Œæˆ!")
        print(f"   ğŸ“ˆ äº¤å‰éªŒè¯RÂ²: {validation_results['cv_r2_mean']:.4f} Â± {validation_results['cv_r2_std']:.4f}")
        print(f"   ğŸ“‰ äº¤å‰éªŒè¯RMSE: {validation_results['cv_rmse_mean']:.4f} Â± {validation_results['cv_rmse_std']:.4f}")
    
    def generate_candidate_points(self, n_candidates: int = 1000, 
                                use_grid: bool = False) -> Tuple[np.ndarray, np.ndarray]:
        """
        ç”Ÿæˆå€™é€‰å®éªŒç‚¹
        
        Args:
            n_candidates: å€™é€‰ç‚¹æ•°é‡
            use_grid: æ˜¯å¦ä½¿ç”¨ç½‘æ ¼é‡‡æ ·
            
        Returns:
            candidates_scaled: æ ‡å‡†åŒ–å€™é€‰ç‚¹
            candidates_original: åŸå§‹å€™é€‰ç‚¹
        """
        print(f"\nğŸ”„ æ­¥éª¤3: å€™é€‰ç‚¹ç”Ÿæˆ...")
        
        if use_grid:
            # ç½‘æ ¼é‡‡æ ·
            self.candidates_scaled, self.candidates_original = \
                self.candidate_generator.generate_grid_candidates(
                    self.variable_bounds, self.scaler
                )
        else:
            # LHSé‡‡æ ·
            self.candidates_scaled, self.candidates_original = \
                self.candidate_generator.generate_candidates(
                    self.variable_bounds, n_candidates, self.scaler
                )
        
        # å¯è¡Œæ€§è¿‡æ»¤
        feasible_mask = self.candidate_generator.filter_feasible_candidates(
            self.candidates_original
        )
        
        self.candidates_scaled = self.candidates_scaled[feasible_mask]
        self.candidates_original = self.candidates_original[feasible_mask]
        
        print(f"âœ… å€™é€‰ç‚¹ç”Ÿæˆå®Œæˆ!")
        print(f"   ğŸ“Š å¯è¡Œå€™é€‰ç‚¹æ•°: {len(self.candidates_original)}")
        
        return self.candidates_scaled, self.candidates_original
    
    def optimize_experiments(self, n_experiments: int = 5, 
                           use_constraints: bool = True,
                           diversity_weight: float = 0.3) -> pd.DataFrame:
        """
        ä¼˜åŒ–å®éªŒè®¾è®¡
        
        Args:
            n_experiments: éœ€è¦è®¾è®¡çš„å®éªŒæ•°é‡
            use_constraints: æ˜¯å¦ä½¿ç”¨çº¦æŸæ¡ä»¶
            diversity_weight: å¤šæ ·æ€§æƒé‡
            
        Returns:
            results_df: å®éªŒè®¾è®¡ç»“æœ
        """
        print(f"\nğŸ”„ æ­¥éª¤4: å®éªŒè®¾è®¡ä¼˜åŒ–...")
        
        # è®¡ç®—EIå€¼
        if use_constraints:
            constraints = {
                'temperature_stability': True,
                'co_loading_cost': True,
                'loading_ratio_stability': True,
                'combination_stability': True
            }
            ei_values = self.ei_optimizer.calculate_constrained_ei(
                self.candidates_scaled, self.gpr_fitted, self.y_best, constraints
            )
        else:
            ei_values = self.ei_optimizer.calculate_ei(
                self.candidates_scaled, self.gpr_fitted, self.y_best
            )
        
        # é€‰æ‹©æœ€ä¼˜å®éªŒç‚¹
        selected_indices, selected_points_scaled, selection_info = \
            self.ei_optimizer.select_optimal_experiments(
                self.candidates_scaled, ei_values, self.gpr_fitted,
                n_experiments, diversity_weight
            )
        
        # è½¬æ¢å›åŸå§‹å°ºåº¦
        selected_points_original = self.candidates_original[selected_indices]
        
        # åˆ†æç»“æœ
        feature_names = ['T', 'total_mass', 'loading_ratio', 'Co_loading', 'ethanol_conc', 'loading_method']
        results_df = self.ei_optimizer.analyze_selection_results(
            selected_points_original, selection_info, feature_names
        )
        
        # æ·»åŠ å®éªŒç¼–å·
        results_df.insert(0, 'experiment_id', [f'NEW_{i+1}' for i in range(len(results_df))])
        
        print(f"âœ… å®éªŒè®¾è®¡ä¼˜åŒ–å®Œæˆ!")
        
        return results_df
    
    def generate_detailed_recommendations(self, results_df: pd.DataFrame) -> pd.DataFrame:
        """ç”Ÿæˆè¯¦ç»†çš„å®éªŒå»ºè®®"""
        print("\nğŸ”„ æ­¥éª¤5: ç”Ÿæˆè¯¦ç»†å®éªŒå»ºè®®...")
        
        # åˆ›å»ºè¯¦ç»†å»ºè®®DataFrame
        detailed_df = results_df.copy()
        
        # è½¬æ¢è£…æ–™æ–¹å¼
        detailed_df['loading_method_name'] = detailed_df['loading_method'].map({
            1: 'è£…æ–™æ–¹å¼I', 2: 'è£…æ–™æ–¹å¼II'
        })
        
        # è®¡ç®—Co/SiO2å’ŒHAPçš„å…·ä½“è´¨é‡
        detailed_df['Co_SiO2_mass'] = detailed_df['total_mass'] * detailed_df['loading_ratio'] / (1 + detailed_df['loading_ratio'])
        detailed_df['HAP_mass'] = detailed_df['total_mass'] - detailed_df['Co_SiO2_mass']
        
        # ç”Ÿæˆå‚¬åŒ–å‰‚ç»„åˆæè¿°
        detailed_df['catalyst_description'] = detailed_df.apply(
            lambda row: f"{row['Co_SiO2_mass']:.1f}mg {row['Co_loading']}wt%Co/SiO2-{row['HAP_mass']:.1f}mg HAP-ä¹™é†‡æµ“åº¦ {row['ethanol_conc']:.2f}ml/min",
            axis=1
        )
        
        # ç”Ÿæˆå®éªŒæ¡ä»¶æ€»ç»“
        detailed_df['experiment_summary'] = detailed_df.apply(
            lambda row: f"æ¸©åº¦{row['T']:.0f}Â°C, {row['catalyst_description']}, {row['loading_method_name']}",
            axis=1
        )
        
        # é¢„æœŸæ”¶ç›Šåˆ†æ
        detailed_df['expected_improvement'] = detailed_df['EI_value']
        detailed_df['improvement_potential'] = detailed_df.apply(
            lambda row: self._categorize_improvement_potential(row['EI_value'], row['predicted_yield']),
            axis=1
        )
        
        # é£é™©è¯„ä¼°
        detailed_df['risk_level'] = detailed_df.apply(
            lambda row: self._assess_risk_level(row),
            axis=1
        )
        
        # å®éªŒä¼˜å…ˆçº§
        detailed_df['priority'] = detailed_df.apply(
            lambda row: self._calculate_priority(row),
            axis=1
        )
        
        print("âœ… è¯¦ç»†å®éªŒå»ºè®®ç”Ÿæˆå®Œæˆ!")
        
        return detailed_df
    
    def _categorize_improvement_potential(self, ei_value: float, predicted_yield: float) -> str:
        """åˆ†ç±»æ”¹è¿›æ½œåŠ›"""
        if ei_value > 0.01 and predicted_yield > self.y_best:
            return "é«˜æ½œåŠ›"
        elif ei_value > 0.005:
            return "ä¸­ç­‰æ½œåŠ›"
        else:
            return "æ¢ç´¢æ€§"
    
    def _assess_risk_level(self, row: pd.Series) -> str:
        """è¯„ä¼°é£é™©æ°´å¹³"""
        risk_score = 0
        
        # æ¸©åº¦é£é™©
        if row['T'] > 400:
            risk_score += 2
        elif row['T'] < 275:
            risk_score += 1
        
        # Coè´Ÿè½½é‡é£é™©
        if row['Co_loading'] >= 5.0:
            risk_score += 2
        
        # è£…æ–™æ¯”é£é™©
        if row['loading_ratio'] < 0.4 or row['loading_ratio'] > 1.8:
            risk_score += 1
        
        # ç»„åˆé£é™©
        if row['T'] > 400 and row['Co_loading'] >= 5.0:
            risk_score += 2
        
        if risk_score >= 4:
            return "é«˜é£é™©"
        elif risk_score >= 2:
            return "ä¸­ç­‰é£é™©"
        else:
            return "ä½é£é™©"
    
    def _calculate_priority(self, row: pd.Series) -> str:
        """è®¡ç®—å®éªŒä¼˜å…ˆçº§"""
        if row['improvement_potential'] == "é«˜æ½œåŠ›" and row['risk_level'] != "é«˜é£é™©":
            return "é«˜ä¼˜å…ˆçº§"
        elif row['improvement_potential'] == "ä¸­ç­‰æ½œåŠ›" or row['risk_level'] == "ä½é£é™©":
            return "ä¸­ç­‰ä¼˜å…ˆçº§"
        else:
            return "ä½ä¼˜å…ˆçº§"
    
    def visualize_results(self, results_df: pd.DataFrame, save_plots: bool = True):
        """å¯è§†åŒ–ç»“æœ"""
        print("\nğŸ”„ æ­¥éª¤6: ç»“æœå¯è§†åŒ–...")
        
        # è®¾ç½®å›¾å½¢æ ·å¼
        plt.style.use('default')
        # ç¡®ä¿ä¸­æ–‡å­—ä½“æ­£ç¡®æ˜¾ç¤º
        plt.rcParams['font.size'] = 10
        fig = plt.figure(figsize=(20, 15))
        
        # 1. EIå€¼åˆ†å¸ƒ
        ax1 = plt.subplot(2, 3, 1)
        plt.bar(range(len(results_df)), results_df['EI_value'], color='skyblue', alpha=0.7)
        plt.xlabel('å®éªŒç¼–å·')
        plt.ylabel('EIå€¼')
        plt.title('æœŸæœ›æ”¹è¿›å€¼åˆ†å¸ƒ')
        plt.xticks(range(len(results_df)), results_df['experiment_id'], rotation=45)
        
        # 2. é¢„æµ‹æ”¶ç‡vsä¸ç¡®å®šæ€§
        ax2 = plt.subplot(2, 3, 2)
        scatter = plt.scatter(results_df['predicted_yield'], results_df['uncertainty'], 
                            c=results_df['EI_value'], cmap='viridis', s=100, alpha=0.7)
        plt.xlabel('é¢„æµ‹æ”¶ç‡')
        plt.ylabel('é¢„æµ‹ä¸ç¡®å®šæ€§')
        plt.title('æ”¶ç‡-ä¸ç¡®å®šæ€§å…³ç³»')
        plt.colorbar(scatter, label='EIå€¼')
        
        # 3. æ¸©åº¦vs Coè´Ÿè½½é‡
        ax3 = plt.subplot(2, 3, 3)
        scatter = plt.scatter(results_df['T'], results_df['Co_loading'], 
                            c=results_df['predicted_yield'], cmap='RdYlBu_r', s=100, alpha=0.7)
        plt.xlabel('æ¸©åº¦ (Â°C)')
        plt.ylabel('Coè´Ÿè½½é‡ (wt%)')
        plt.title('æ¸©åº¦-Coè´Ÿè½½é‡åˆ†å¸ƒ')
        plt.colorbar(scatter, label='é¢„æµ‹æ”¶ç‡')
        
        # 4. è£…æ–™æ¯”åˆ†å¸ƒ
        ax4 = plt.subplot(2, 3, 4)
        plt.hist(results_df['loading_ratio'], bins=10, alpha=0.7, color='lightcoral')
        plt.xlabel('Co/SiO2å’ŒHAPè£…æ–™æ¯”')
        plt.ylabel('é¢‘æ¬¡')
        plt.title('è£…æ–™æ¯”åˆ†å¸ƒ')
        
        # 5. æ”¹è¿›æ½œåŠ›é¥¼å›¾
        ax5 = plt.subplot(2, 3, 5)
        if 'improvement_potential' in results_df.columns:
            potential_counts = results_df['improvement_potential'].value_counts()
            plt.pie(potential_counts.values, labels=potential_counts.index, autopct='%1.1f%%')
            plt.title('æ”¹è¿›æ½œåŠ›åˆ†å¸ƒ')
        
        # 6. é£é™©æ°´å¹³åˆ†å¸ƒ
        ax6 = plt.subplot(2, 3, 6)
        if 'risk_level' in results_df.columns:
            risk_counts = results_df['risk_level'].value_counts()
            colors = ['green', 'orange', 'red'][:len(risk_counts)]
            plt.bar(risk_counts.index, risk_counts.values, color=colors, alpha=0.7)
            plt.xlabel('é£é™©æ°´å¹³')
            plt.ylabel('å®éªŒæ•°é‡')
            plt.title('é£é™©æ°´å¹³åˆ†å¸ƒ')
        
        plt.tight_layout()
        
        if save_plots:
            plt.savefig('experiment_design_analysis.png', dpi=300, bbox_inches='tight')
            print("ğŸ“Š å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜: experiment_design_analysis.png")
        
        plt.show()
        
        print("âœ… ç»“æœå¯è§†åŒ–å®Œæˆ!")
    
    def save_results(self, results_df: pd.DataFrame, detailed_df: pd.DataFrame = None):
        """ä¿å­˜ç»“æœ"""
        print("\nğŸ”„ æ­¥éª¤7: ä¿å­˜ç»“æœ...")
        
        # ä¿å­˜åŸºç¡€ç»“æœ
        results_df.to_csv('experiment_design_results.csv', index=False, encoding='utf-8-sig')
        print("ğŸ’¾ åŸºç¡€ç»“æœå·²ä¿å­˜: experiment_design_results.csv")
        
        # ä¿å­˜è¯¦ç»†å»ºè®®
        if detailed_df is not None:
            detailed_df.to_csv('detailed_experiment_recommendations.csv', index=False, encoding='utf-8-sig')
            print("ğŸ’¾ è¯¦ç»†å»ºè®®å·²ä¿å­˜: detailed_experiment_recommendations.csv")
        
        # ç”Ÿæˆå®éªŒæŠ¥å‘Š
        self._generate_experiment_report(results_df, detailed_df)
        
        print("âœ… ç»“æœä¿å­˜å®Œæˆ!")
    
    def _generate_experiment_report(self, results_df: pd.DataFrame, detailed_df: pd.DataFrame = None):
        """ç”Ÿæˆå®éªŒæŠ¥å‘Š"""
        report_content = []
        report_content.append("# ä¹™é†‡å¶åˆåˆ¶å¤‡C4çƒ¯çƒƒ - å®éªŒè®¾è®¡æŠ¥å‘Š\n")
        report_content.append("## 1. å®éªŒè®¾è®¡æ¦‚è¿°\n")
        report_content.append(f"- **è®¾è®¡æ–¹æ³•**: åŸºäºGPRæ¨¡å‹å’ŒEIå‡†åˆ™çš„å®éªŒè®¾è®¡")
        report_content.append(f"- **å®éªŒæ•°é‡**: {len(results_df)}ä¸ªæ–°å®éªŒ")
        report_content.append(f"- **å½“å‰æœ€ä½³æ”¶ç‡**: {self.y_best:.4f}")
        report_content.append(f"- **é¢„æœŸæœ€é«˜æ”¶ç‡**: {results_df['predicted_yield'].max():.4f}\n")
        
        report_content.append("## 2. æ¨èå®éªŒæ¡ä»¶\n")
        for i, row in results_df.iterrows():
            report_content.append(f"### å®éªŒ {row['experiment_id']}")
            report_content.append(f"- **æ¸©åº¦**: {row['T']:.0f}Â°C")
            report_content.append(f"- **Coè´Ÿè½½é‡**: {row['Co_loading']:.1f}wt%")
            report_content.append(f"- **è£…æ–™æ¯”**: {row['loading_ratio']:.2f}")
            report_content.append(f"- **ä¹™é†‡æµ“åº¦**: {row['ethanol_conc']:.2f}ml/min")
            report_content.append(f"- **è£…æ–™æ–¹å¼**: {'I' if row['loading_method']==1 else 'II'}")
            report_content.append(f"- **é¢„æµ‹æ”¶ç‡**: {row['predicted_yield']:.4f} Â± {row['uncertainty']:.4f}")
            report_content.append(f"- **EIå€¼**: {row['EI_value']:.6f}")
            report_content.append(f"- **é€‰æ‹©ç†ç”±**: {row['selection_reason']}\n")
        
        if detailed_df is not None:
            report_content.append("## 3. å®éªŒå»ºè®®æ€»ç»“\n")
            report_content.append("| å®éªŒID | ä¼˜å…ˆçº§ | æ”¹è¿›æ½œåŠ› | é£é™©æ°´å¹³ | å®éªŒæ¡ä»¶æ€»ç»“ |")
            report_content.append("|--------|--------|----------|----------|--------------|")
            for _, row in detailed_df.iterrows():
                report_content.append(f"| {row['experiment_id']} | {row['priority']} | {row['improvement_potential']} | {row['risk_level']} | {row['experiment_summary']} |")
        
        report_content.append("\n## 4. å®éªŒæ‰§è¡Œå»ºè®®\n")
        report_content.append("1. **ä¼˜å…ˆæ‰§è¡Œé«˜ä¼˜å…ˆçº§å®éªŒ**ï¼Œè¿™äº›å®éªŒå…·æœ‰æœ€é«˜çš„é¢„æœŸæ”¶ç›Š")
        report_content.append("2. **æ³¨æ„é«˜é£é™©å®éªŒçš„å®‰å…¨æªæ–½**ï¼Œç‰¹åˆ«æ˜¯é«˜æ¸©å’Œé«˜Coè´Ÿè½½é‡æ¡ä»¶")
        report_content.append("3. **å»ºè®®åˆ†æ‰¹æ‰§è¡Œ**ï¼Œå…ˆæ‰§è¡Œ2-3ä¸ªå®éªŒéªŒè¯æ¨¡å‹é¢„æµ‹å‡†ç¡®æ€§")
        report_content.append("4. **è®°å½•è¯¦ç»†çš„å®éªŒæ•°æ®**ï¼Œç”¨äºåç»­æ¨¡å‹ä¼˜åŒ–")
        
        # ä¿å­˜æŠ¥å‘Š
        with open('experiment_design_report.md', 'w', encoding='utf-8') as f:
            f.write('\n'.join(report_content))
        
        print("ğŸ“‹ å®éªŒæŠ¥å‘Šå·²ä¿å­˜: experiment_design_report.md")
    
    def run_complete_design(self, n_experiments: int = 5, n_candidates: int = 1000,
                          use_constraints: bool = True, diversity_weight: float = 0.3,
                          save_plots: bool = True) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """
        è¿è¡Œå®Œæ•´çš„å®éªŒè®¾è®¡æµç¨‹
        
        Args:
            n_experiments: å®éªŒæ•°é‡
            n_candidates: å€™é€‰ç‚¹æ•°é‡
            use_constraints: æ˜¯å¦ä½¿ç”¨çº¦æŸ
            diversity_weight: å¤šæ ·æ€§æƒé‡
            save_plots: æ˜¯å¦ä¿å­˜å›¾è¡¨
            
        Returns:
            results_df: åŸºç¡€ç»“æœ
            detailed_df: è¯¦ç»†å»ºè®®
        """
        print("ğŸš€ å¼€å§‹å®Œæ•´å®éªŒè®¾è®¡æµç¨‹...\n")
        
        try:
            # 1. æ•°æ®å¤„ç†
            self.load_and_process_data()
            
            # 2. æ¨¡å‹è®­ç»ƒ
            self.build_gpr_model()
            
            # 3. å€™é€‰ç‚¹ç”Ÿæˆ
            self.generate_candidate_points(n_candidates)
            
            # 4. å®éªŒä¼˜åŒ–
            results_df = self.optimize_experiments(n_experiments, use_constraints, diversity_weight)
            
            # 5. è¯¦ç»†å»ºè®®
            detailed_df = self.generate_detailed_recommendations(results_df)
            
            # 6. å¯è§†åŒ–
            self.visualize_results(detailed_df, save_plots)
            
            # 7. ä¿å­˜ç»“æœ
            self.save_results(results_df, detailed_df)
            
            print("\nğŸ‰ å®éªŒè®¾è®¡æµç¨‹å®Œæˆ!")
            print("ğŸ“‹ è¯·æŸ¥çœ‹ç”Ÿæˆçš„æ–‡ä»¶:")
            print("   - experiment_design_results.csv: åŸºç¡€ç»“æœ")
            print("   - detailed_experiment_recommendations.csv: è¯¦ç»†å»ºè®®")
            print("   - experiment_design_report.md: å®éªŒæŠ¥å‘Š")
            if save_plots:
                print("   - experiment_design_analysis.png: åˆ†æå›¾è¡¨")
            
            return results_df, detailed_df
            
        except Exception as e:
            print(f"âŒ å®éªŒè®¾è®¡æµç¨‹å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None, None

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§ª ä¹™é†‡å¶åˆåˆ¶å¤‡C4çƒ¯çƒƒ - å®éªŒè®¾è®¡ç³»ç»Ÿ")
    print("=" * 50)
    
    # åˆ›å»ºå®éªŒè®¾è®¡å™¨
    designer = ExperimentDesigner(random_state=42)
    
    # è¿è¡Œå®Œæ•´è®¾è®¡æµç¨‹
    results_df, detailed_df = designer.run_complete_design(
        n_experiments=5,
        n_candidates=1000,
        use_constraints=True,
        diversity_weight=0.3,
        save_plots=True
    )
    
    if results_df is not None:
        print("\nğŸ“Š å®éªŒè®¾è®¡ç»“æœé¢„è§ˆ:")
        print(results_df[['experiment_id', 'T', 'Co_loading', 'predicted_yield', 'EI_value']].to_string(index=False))

if __name__ == "__main__":
    main()