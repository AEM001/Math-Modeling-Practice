#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
EIä¼˜åŒ–æ¨¡å— - GPRå®éªŒè®¾è®¡ç³»ç»Ÿ
åŠŸèƒ½ï¼šè®¡ç®—æœŸæœ›æ”¹è¿›(Expected Improvement)å¹¶é€‰æ‹©æœ€ä¼˜å®éªŒç‚¹
"""

import numpy as np
import pandas as pd
from scipy.stats import norm
from typing import Tuple, List, Dict
import warnings
warnings.filterwarnings('ignore')

class EIOptimizer:
    """æœŸæœ›æ”¹è¿›ä¼˜åŒ–å™¨"""
    
    def __init__(self, xi: float = 0.01):
        """
        åˆå§‹åŒ–EIä¼˜åŒ–å™¨
        
        Args:
            xi: æ¢ç´¢å‚æ•°ï¼Œæ§åˆ¶æ¢ç´¢ä¸åˆ©ç”¨çš„å¹³è¡¡
        """
        self.xi = xi
        
    def calculate_ei(self, X: np.ndarray, gpr_model, y_best: float) -> np.ndarray:
        """
        è®¡ç®—æœŸæœ›æ”¹è¿›å€¼
        
        Args:
            X: å€™é€‰ç‚¹çŸ©é˜µ (n_samples, n_features)
            gpr_model: è®­ç»ƒå¥½çš„GPRæ¨¡å‹
            y_best: å½“å‰æœ€ä½³æ”¶ç‡å€¼
            
        Returns:
            ei_values: EIå€¼æ•°ç»„
        """
        print(f"ğŸ”„ è®¡ç®—{len(X)}ä¸ªå€™é€‰ç‚¹çš„EIå€¼...")
        
        # è·å–GPRé¢„æµ‹
        mu, sigma = gpr_model.predict(X, return_std=True)
        
        # é¿å…æ•°å€¼é—®é¢˜
        sigma = np.maximum(sigma, 1e-9)
        
        # è®¡ç®—æ”¹è¿›é‡
        improvement = mu - y_best - self.xi
        
        # æ ‡å‡†åŒ–æ”¹è¿›é‡
        Z = improvement / sigma
        
        # è®¡ç®—EIå€¼
        ei_values = improvement * norm.cdf(Z) + sigma * norm.pdf(Z)
        
        # å¤„ç†æ•°å€¼å¼‚å¸¸
        ei_values = np.maximum(ei_values, 0)
        
        print(f"âœ… EIè®¡ç®—å®Œæˆ")
        print(f"   ğŸ“Š EIå€¼èŒƒå›´: [{ei_values.min():.6f}, {ei_values.max():.6f}]")
        print(f"   ğŸ“ˆ å¹³å‡EIå€¼: {ei_values.mean():.6f}")
        
        return ei_values
    
    def calculate_constrained_ei(self, X: np.ndarray, gpr_model, y_best: float,
                                constraints: Dict = None) -> np.ndarray:
        """
        è®¡ç®—å¸¦çº¦æŸçš„æœŸæœ›æ”¹è¿›å€¼
        
        Args:
            X: å€™é€‰ç‚¹çŸ©é˜µ
            gpr_model: GPRæ¨¡å‹
            y_best: å½“å‰æœ€ä½³å€¼
            constraints: çº¦æŸæ¡ä»¶å­—å…¸
            
        Returns:
            constrained_ei: çº¦æŸåçš„EIå€¼
        """
        # åŸºç¡€EIè®¡ç®—
        ei_values = self.calculate_ei(X, gpr_model, y_best)
        
        if constraints is None:
            return ei_values
        
        print("ğŸ”’ åº”ç”¨çº¦æŸæ¡ä»¶...")
        
        # åº”ç”¨çº¦æŸæƒ©ç½š
        penalty_factors = self._calculate_constraint_penalties(X, constraints)
        constrained_ei = ei_values * penalty_factors
        
        print(f"   ğŸ“‰ çº¦æŸåEIå€¼èŒƒå›´: [{constrained_ei.min():.6f}, {constrained_ei.max():.6f}]")
        
        return constrained_ei
    
    def _calculate_constraint_penalties(self, X: np.ndarray, constraints: Dict) -> np.ndarray:
        """è®¡ç®—çº¦æŸæƒ©ç½šå› å­"""
        n_samples = len(X)
        penalty_factors = np.ones(n_samples)
        
        # å˜é‡ç´¢å¼•æ˜ å°„
        var_indices = {
            'T': 0, 'total_mass': 1, 'loading_ratio': 2,
            'Co_loading': 3, 'ethanol_conc': 4, 'loading_method': 5
        }
        
        for i in range(n_samples):
            penalty = 1.0
            candidate = X[i]
            
            # æ¸©åº¦çº¦æŸ
            T = candidate[var_indices['T']]
            if 'temperature_stability' in constraints:
                if T > 400:
                    penalty *= 0.8  # é«˜æ¸©ç¨³å®šæ€§æƒ©ç½š
                if T < 275:
                    penalty *= 0.9  # ä½æ¸©æ´»æ€§æƒ©ç½š
            
            # Coè´Ÿè½½é‡çº¦æŸ
            Co_loading = candidate[var_indices['Co_loading']]
            if 'co_loading_cost' in constraints:
                if Co_loading >= 5.0:
                    penalty *= 0.7  # é«˜è´Ÿè½½é‡æˆæœ¬æƒ©ç½š
            
            # è£…æ–™æ¯”çº¦æŸ
            loading_ratio = candidate[var_indices['loading_ratio']]
            if 'loading_ratio_stability' in constraints:
                if loading_ratio < 0.4 or loading_ratio > 1.8:
                    penalty *= 0.6  # æç«¯è£…æ–™æ¯”æƒ©ç½š
            
            # ç»„åˆçº¦æŸ
            if 'combination_stability' in constraints:
                if T > 400 and Co_loading >= 5.0:
                    penalty *= 0.5  # é«˜æ¸©é«˜è´Ÿè½½ç»„åˆæƒ©ç½š
                if T > 350 and (loading_ratio < 0.4 or loading_ratio > 1.8):
                    penalty *= 0.6  # é«˜æ¸©æç«¯è£…æ–™æ¯”æƒ©ç½š
            
            penalty_factors[i] = penalty
        
        return penalty_factors
    
    def select_optimal_experiments(self, X: np.ndarray, ei_values: np.ndarray,
                                 gpr_model, n_experiments: int = 5,
                                 diversity_weight: float = 0.3) -> Tuple[np.ndarray, np.ndarray, Dict]:
        """
        é€‰æ‹©æœ€ä¼˜å®éªŒç‚¹
        
        Args:
            X: å€™é€‰ç‚¹çŸ©é˜µ
            ei_values: EIå€¼æ•°ç»„
            gpr_model: GPRæ¨¡å‹
            n_experiments: éœ€è¦é€‰æ‹©çš„å®éªŒæ•°é‡
            diversity_weight: å¤šæ ·æ€§æƒé‡
            
        Returns:
            selected_indices: é€‰ä¸­ç‚¹çš„ç´¢å¼•
            selected_points: é€‰ä¸­çš„å®éªŒç‚¹
            selection_info: é€‰æ‹©ä¿¡æ¯
        """
        print(f"ğŸ¯ é€‰æ‹©{n_experiments}ä¸ªæœ€ä¼˜å®éªŒç‚¹...")
        
        selected_indices = []
        remaining_indices = np.arange(len(X))
        selection_info = {
            'ei_values': [],
            'predicted_yields': [],
            'uncertainties': [],
            'diversity_scores': []
        }
        
        for i in range(n_experiments):
            print(f"  ğŸ” é€‰æ‹©ç¬¬{i+1}ä¸ªå®éªŒç‚¹...")
            
            if i == 0:
                # ç¬¬ä¸€ä¸ªç‚¹ï¼šé€‰æ‹©EIå€¼æœ€é«˜çš„
                best_idx = np.argmax(ei_values[remaining_indices])
                selected_idx = remaining_indices[best_idx]
            else:
                # åç»­ç‚¹ï¼šè€ƒè™‘EIå€¼å’Œå¤šæ ·æ€§
                scores = self._calculate_selection_scores(
                    X, ei_values, remaining_indices, selected_indices,
                    gpr_model, diversity_weight
                )
                best_idx = np.argmax(scores)
                selected_idx = remaining_indices[best_idx]
            
            # è®°å½•é€‰æ‹©ä¿¡æ¯
            mu, sigma = gpr_model.predict(X[selected_idx:selected_idx+1], return_std=True)
            
            selection_info['ei_values'].append(ei_values[selected_idx])
            selection_info['predicted_yields'].append(mu[0])
            selection_info['uncertainties'].append(sigma[0])
            
            if i > 0:
                diversity_score = self._calculate_diversity_score(
                    X[selected_idx], X[selected_indices]
                )
                selection_info['diversity_scores'].append(diversity_score)
            else:
                selection_info['diversity_scores'].append(0.0)
            
            # æ›´æ–°é€‰æ‹©åˆ—è¡¨
            selected_indices.append(selected_idx)
            remaining_indices = np.delete(remaining_indices, best_idx)
            
            print(f"    âœ… é€‰ä¸­ç‚¹{selected_idx}: EI={ei_values[selected_idx]:.6f}, "
                  f"é¢„æµ‹æ”¶ç‡={mu[0]:.4f}Â±{sigma[0]:.4f}")
        
        selected_points = X[selected_indices]
        
        print(f"ğŸ‰ å®éªŒç‚¹é€‰æ‹©å®Œæˆï¼")
        
        return np.array(selected_indices), selected_points, selection_info
    
    def _calculate_selection_scores(self, X: np.ndarray, ei_values: np.ndarray,
                                  remaining_indices: np.ndarray, selected_indices: List[int],
                                  gpr_model, diversity_weight: float) -> np.ndarray:
        """è®¡ç®—é€‰æ‹©åˆ†æ•°ï¼ˆEI + å¤šæ ·æ€§ï¼‰"""
        scores = np.zeros(len(remaining_indices))
        
        for i, idx in enumerate(remaining_indices):
            # EIåˆ†æ•°ï¼ˆå½’ä¸€åŒ–ï¼‰
            ei_score = ei_values[idx] / np.max(ei_values)
            
            # å¤šæ ·æ€§åˆ†æ•°
            diversity_score = self._calculate_diversity_score(
                X[idx], X[selected_indices]
            )
            
            # ç»¼åˆåˆ†æ•°
            scores[i] = (1 - diversity_weight) * ei_score + diversity_weight * diversity_score
        
        return scores
    
    def _calculate_diversity_score(self, candidate: np.ndarray, selected_points: np.ndarray) -> float:
        """è®¡ç®—å¤šæ ·æ€§åˆ†æ•°"""
        if len(selected_points) == 0:
            return 1.0
        
        # è®¡ç®—åˆ°å·²é€‰ç‚¹çš„æœ€å°è·ç¦»
        distances = np.linalg.norm(selected_points - candidate, axis=1)
        min_distance = np.min(distances)
        
        # å½’ä¸€åŒ–å¤šæ ·æ€§åˆ†æ•°
        max_possible_distance = np.sqrt(len(candidate))  # å‡è®¾ç‰¹å¾å·²æ ‡å‡†åŒ–
        diversity_score = min_distance / max_possible_distance
        
        return diversity_score
    
    def analyze_selection_results(self, selected_points: np.ndarray, selection_info: Dict,
                                feature_names: List[str]) -> pd.DataFrame:
        """åˆ†æé€‰æ‹©ç»“æœ"""
        print("ğŸ“Š åˆ†æå®éªŒç‚¹é€‰æ‹©ç»“æœ...")
        
        # åˆ›å»ºç»“æœDataFrame
        results_df = pd.DataFrame(selected_points, columns=feature_names)
        results_df['EI_value'] = selection_info['ei_values']
        results_df['predicted_yield'] = selection_info['predicted_yields']
        results_df['uncertainty'] = selection_info['uncertainties']
        results_df['diversity_score'] = selection_info['diversity_scores']
        
        # è®¡ç®—é€‰æ‹©ç†ç”±
        results_df['selection_reason'] = self._generate_selection_reasons(
            results_df, feature_names
        )
        
        print("âœ… ç»“æœåˆ†æå®Œæˆ")
        
        return results_df
    
    def _generate_selection_reasons(self, results_df: pd.DataFrame, 
                                  feature_names: List[str]) -> List[str]:
        """ç”Ÿæˆé€‰æ‹©ç†ç”±"""
        reasons = []
        
        for i, row in results_df.iterrows():
            reason_parts = []
            
            # EIå€¼åˆ†æ
            if row['EI_value'] > results_df['EI_value'].mean():
                reason_parts.append("é«˜EIå€¼")
            
            # é¢„æµ‹æ”¶ç‡åˆ†æ
            if row['predicted_yield'] > results_df['predicted_yield'].mean():
                reason_parts.append("é«˜é¢„æµ‹æ”¶ç‡")
            
            # ä¸ç¡®å®šæ€§åˆ†æ
            if row['uncertainty'] > results_df['uncertainty'].mean():
                reason_parts.append("é«˜ä¸ç¡®å®šæ€§åŒºåŸŸ")
            
            # å¤šæ ·æ€§åˆ†æ
            if i > 0 and row['diversity_score'] > 0.5:
                reason_parts.append("å¢å¼ºå¤šæ ·æ€§")
            
            # ç‰¹æ®Šæ¡ä»¶åˆ†æ
            if row['T'] > 400:
                reason_parts.append("é«˜æ¸©æ¡ä»¶æ¢ç´¢")
            if row['Co_loading'] >= 5.0:
                reason_parts.append("é«˜Coè´Ÿè½½æ¢ç´¢")
            
            if not reason_parts:
                reason_parts.append("ç»¼åˆä¼˜åŒ–é€‰æ‹©")
            
            reasons.append(" + ".join(reason_parts))
        
        return reasons
    
    def save_results(self, results_df: pd.DataFrame, filepath: str):
        """ä¿å­˜é€‰æ‹©ç»“æœ"""
        results_df.to_csv(filepath, index=False, encoding='utf-8-sig')
        print(f"ğŸ’¾ å®éªŒè®¾è®¡ç»“æœå·²ä¿å­˜: {filepath}")

def main():
    """æµ‹è¯•EIä¼˜åŒ–æ¨¡å—"""
    print("ğŸ§ª æµ‹è¯•EIä¼˜åŒ–æ¨¡å—...")
    
    try:
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        np.random.seed(42)
        n_candidates = 100
        n_features = 6
        
        X_test = np.random.randn(n_candidates, n_features)
        y_best = 0.15  # å‡è®¾å½“å‰æœ€ä½³æ”¶ç‡ä¸º15%
        
        # æ¨¡æ‹ŸGPRæ¨¡å‹é¢„æµ‹
        class MockGPRModel:
            def predict(self, X, return_std=False):
                mu = 0.1 + 0.05 * np.random.randn(len(X))
                if return_std:
                    sigma = 0.02 + 0.01 * np.random.rand(len(X))
                    return mu, sigma
                return mu
        
        mock_model = MockGPRModel()
        
        # æµ‹è¯•EIè®¡ç®—
        optimizer = EIOptimizer(xi=0.01)
        ei_values = optimizer.calculate_ei(X_test, mock_model, y_best)
        
        # æµ‹è¯•çº¦æŸEI
        constraints = {
            'temperature_stability': True,
            'co_loading_cost': True,
            'combination_stability': True
        }
        constrained_ei = optimizer.calculate_constrained_ei(
            X_test, mock_model, y_best, constraints
        )
        
        # æµ‹è¯•å®éªŒç‚¹é€‰æ‹©
        selected_indices, selected_points, selection_info = optimizer.select_optimal_experiments(
            X_test, constrained_ei, mock_model, n_experiments=5
        )
        
        # åˆ†æç»“æœ
        feature_names = ['T', 'total_mass', 'loading_ratio', 'Co_loading', 'ethanol_conc', 'loading_method']
        results_df = optimizer.analyze_selection_results(
            selected_points, selection_info, feature_names
        )
        
        print("\nğŸ“Š é€‰æ‹©ç»“æœ:")
        print(results_df)
        
        # ä¿å­˜ç»“æœ
        optimizer.save_results(results_df, 'test_experiment_design.csv')
        
        print("\nâœ… EIä¼˜åŒ–æ¨¡å—æµ‹è¯•é€šè¿‡ï¼")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()