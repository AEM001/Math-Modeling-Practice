#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®å¤„ç†æ¨¡å— - GPRå®éªŒè®¾è®¡ç³»ç»Ÿ
åŠŸèƒ½ï¼šæ•°æ®åŠ è½½ã€æ¸…æ´—ã€ç‰¹å¾å·¥ç¨‹ã€æ ‡å‡†åŒ–
"""

import pandas as pd
import numpy as np
import re
from sklearn.preprocessing import StandardScaler, LabelEncoder
from typing import Tuple, Dict, List
import warnings
warnings.filterwarnings('ignore')

class DataProcessor:
    """æ•°æ®å¤„ç†å™¨ç±»"""
    
    def __init__(self):
        self.scaler = StandardScaler()
        self.feature_names = ['T', 'total_mass', 'loading_ratio', 'Co_loading', 'ethanol_conc', 'loading_method']
        self.target_name = 'C4_yield'
        
    def load_and_prepare_data(self, attachment1_path: str, indicators_path: str) -> Tuple[np.ndarray, np.ndarray, Dict]:
        """
        åŠ è½½å¹¶é¢„å¤„ç†æ•°æ®
        
        Args:
            attachment1_path: é™„ä»¶1.csvè·¯å¾„
            indicators_path: æ¯ç»„æŒ‡æ ‡.csvè·¯å¾„
            
        Returns:
            X: ç‰¹å¾çŸ©é˜µ (æ ‡å‡†åŒ–å)
            y: ç›®æ ‡å˜é‡ (C4çƒ¯çƒƒæ”¶ç‡)
            data_info: æ•°æ®ä¿¡æ¯å­—å…¸
        """
        print("ğŸ”„ å¼€å§‹æ•°æ®åŠ è½½ä¸é¢„å¤„ç†...")
        
        # 1. åŠ è½½é™„ä»¶1æ•°æ®
        print("  ğŸ“‚ åŠ è½½é™„ä»¶1æ•°æ®...")
        attachment1 = pd.read_csv(attachment1_path)
        
        # 2. è®¡ç®—C4çƒ¯çƒƒæ”¶ç‡
        print("  ğŸ§® è®¡ç®—C4çƒ¯çƒƒæ”¶ç‡...")
        attachment1['C4_yield'] = (attachment1['ä¹™é†‡è½¬åŒ–ç‡(%)'] * attachment1['C4çƒ¯çƒƒé€‰æ‹©æ€§(%)']) / 100
        
        # 3. åŠ è½½å¹¶æ¸…æ´—æ¯ç»„æŒ‡æ ‡æ•°æ®
        print("  ğŸ“‚ åŠ è½½æ¯ç»„æŒ‡æ ‡æ•°æ®...")
        indicators = pd.read_csv(indicators_path)
        indicators_cleaned = self._clean_indicators_data(indicators)
        
        # 4. åˆå¹¶æ•°æ®
        print("  ğŸ”— åˆå¹¶æ•°æ®è¡¨...")
        merged_data = pd.merge(attachment1, indicators_cleaned, on='å‚¬åŒ–å‰‚ç»„åˆç¼–å·', how='left')
        
        # 5. ç‰¹å¾å·¥ç¨‹
        print("  âš™ï¸ è¿›è¡Œç‰¹å¾å·¥ç¨‹...")
        processed_data = self._feature_engineering(merged_data)
        
        # 6. æ•°æ®æ¸…æ´—å’ŒéªŒè¯
        print("  ğŸ§¹ æ•°æ®æ¸…æ´—...")
        clean_data = self._clean_data(processed_data)
        
        # 7. å‡†å¤‡è®­ç»ƒæ•°æ®
        print("  ğŸ“Š å‡†å¤‡è®­ç»ƒæ•°æ®...")
        X, y, data_info = self._prepare_training_data(clean_data)
        
        print(f"âœ… æ•°æ®é¢„å¤„ç†å®Œæˆï¼")
        print(f"   ğŸ“ˆ æ ·æœ¬æ•°é‡: {len(X)}")
        print(f"   ğŸ“‹ ç‰¹å¾ç»´åº¦: {X.shape[1]}")
        print(f"   ğŸ¯ æ”¶ç‡èŒƒå›´: {y.min():.4f} - {y.max():.4f}")
        
        return X, y, data_info
    
    def _clean_indicators_data(self, indicators: pd.DataFrame) -> pd.DataFrame:
        """æ¸…æ´—æ¯ç»„æŒ‡æ ‡æ•°æ®"""
        indicators_clean = indicators.copy()
        
        # æ¸…æ´—æ•°å€¼åˆ—ï¼Œå»é™¤å•ä½
        def extract_numeric(text):
            if pd.isna(text):
                return np.nan
            # æå–æ•°å­—éƒ¨åˆ†
            numbers = re.findall(r'\d+\.?\d*', str(text))
            return float(numbers[0]) if numbers else np.nan
        
        # æ¸…æ´—å„åˆ—
        indicators_clean['Co_SiO2_mass'] = indicators_clean['Co/SiO2ç”¨é‡'].apply(extract_numeric)
        indicators_clean['HAP_mass'] = indicators_clean['HAPç”¨é‡'].apply(extract_numeric)
        indicators_clean['Co_loading'] = indicators_clean['Coè´Ÿè½½é‡'].apply(extract_numeric)
        indicators_clean['ethanol_conc'] = indicators_clean['ä¹™é†‡æµ“åº¦'].apply(extract_numeric)
        
        return indicators_clean
    
    def _feature_engineering(self, data: pd.DataFrame) -> pd.DataFrame:
        """ç‰¹å¾å·¥ç¨‹"""
        processed = data.copy()
        
        # è®¡ç®—æ€»è´¨é‡ (Co/SiO2 å’Œ HAP è´¨é‡ä¹‹å’Œ)
        processed['total_mass'] = processed['Co_SiO2_mass'] + processed['HAP_mass']
        
        # è®¡ç®—è£…æ–™æ¯” (Co/SiO2 å’Œ HAP è£…æ–™æ¯”)
        processed['loading_ratio'] = processed['Co_SiO2_mass'] / processed['HAP_mass']
        
        # åˆ›å»ºè£…æ–™æ–¹å¼å“‘å˜é‡ (A=0, B=1)
        processed['loading_method'] = processed['å‚¬åŒ–å‰‚ç»„åˆç¼–å·'].str[0].map({'A': 0, 'B': 1})
        
        # é‡å‘½åæ¸©åº¦åˆ—
        processed['T'] = processed['æ¸©åº¦']
        
        return processed
    
    def _clean_data(self, data: pd.DataFrame) -> pd.DataFrame:
        """æ•°æ®æ¸…æ´—"""
        clean_data = data.copy()
        
        # ç§»é™¤ç¼ºå¤±å€¼
        clean_data = clean_data.dropna(subset=['C4_yield', 'T', 'total_mass', 'loading_ratio', 
                                              'Co_loading', 'ethanol_conc', 'loading_method'])
        
        # ä¿®æ­£ï¼šå¯¹äºå°æ•°æ®é›†ï¼ŒIQRæ–¹æ³•å¯èƒ½è¿‡äºæ¿€è¿›ï¼Œæš‚æ—¶ç¦ç”¨ä»¥ä¿ç•™æ‰€æœ‰æ•°æ®ç‚¹
        # Q1 = clean_data['C4_yield'].quantile(0.25)
        # Q3 = clean_data['C4_yield'].quantile(0.75)
        # IQR = Q3 - Q1
        # lower_bound = Q1 - 1.5 * IQR
        # upper_bound = Q3 + 1.5 * IQR
        
        # # ä¿ç•™åˆç†èŒƒå›´å†…çš„æ•°æ®
        # clean_data = clean_data[(clean_data['C4_yield'] >= max(0, lower_bound)) & 
        #                        (clean_data['C4_yield'] <= upper_bound)]
        
        return clean_data
    
    def _prepare_training_data(self, data: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray, Dict]:
        """å‡†å¤‡è®­ç»ƒæ•°æ®"""
        # é€‰æ‹©ç‰¹å¾åˆ—
        X = data[self.feature_names].values
        y = data[self.target_name].values
        
        # æ ‡å‡†åŒ–ç‰¹å¾
        X_scaled = self.scaler.fit_transform(X)
        
        # æ•°æ®ä¿¡æ¯
        data_info = {
            'feature_names': self.feature_names,
            'target_name': self.target_name,
            'n_samples': len(X),
            'n_features': X.shape[1],
            'feature_ranges': self._get_feature_ranges(data),
            'target_stats': {
                'min': float(y.min()),
                'max': float(y.max()),
                'mean': float(y.mean()),
                'std': float(y.std())
            },
            'scaler_params': {
                'mean': self.scaler.mean_.tolist(),
                'scale': self.scaler.scale_.tolist()
            }
        }
        
        return X_scaled, y, data_info
    
    def _get_feature_ranges(self, data: pd.DataFrame) -> Dict:
        """è·å–ç‰¹å¾èŒƒå›´"""
        ranges = {}
        for feature in self.feature_names:
            if feature in ['Co_loading', 'ethanol_conc', 'loading_method']:
                # ç¦»æ•£å˜é‡
                ranges[feature] = {
                    'type': 'discrete',
                    'values': sorted(data[feature].unique().tolist())
                }
            else:
                # è¿ç»­å˜é‡
                ranges[feature] = {
                    'type': 'continuous',
                    'min': float(data[feature].min()),
                    'max': float(data[feature].max())
                }
        return ranges
    
    def get_variable_bounds(self) -> Dict:
        """è·å–å˜é‡è¾¹ç•Œï¼ˆç”¨äºå€™é€‰ç‚¹ç”Ÿæˆï¼‰"""
        bounds = {
            'T': (250.0, 450.0),
            'total_mass': (20.0, 400.0),
            'loading_ratio': (0.33, 2.03),
            'Co_loading': [0.5, 1.0, 2.0, 5.0],  # ç¦»æ•£å€¼
            'ethanol_conc': [0.3, 0.9, 1.68, 2.1],  # ç¦»æ•£å€¼
            'loading_method': [0, 1]  # ç¦»æ•£å€¼
        }
        return bounds
    
    def transform_features(self, X: np.ndarray) -> np.ndarray:
        """æ ‡å‡†åŒ–ç‰¹å¾ï¼ˆç”¨äºæ–°æ•°æ®ï¼‰"""
        return self.scaler.transform(X)
    
    def inverse_transform_features(self, X_scaled: np.ndarray) -> np.ndarray:
        """åæ ‡å‡†åŒ–ç‰¹å¾"""
        return self.scaler.inverse_transform(X_scaled)

def main():
    """æµ‹è¯•æ•°æ®å¤„ç†æ¨¡å—"""
    processor = DataProcessor()
    
    # æµ‹è¯•æ•°æ®åŠ è½½
    try:
        X, y, data_info = processor.load_and_prepare_data('é™„ä»¶1.csv', 'æ¯ç»„æŒ‡æ ‡.csv')
        
        print("\nğŸ“Š æ•°æ®ä¿¡æ¯:")
        print(f"ç‰¹å¾åç§°: {data_info['feature_names']}")
        print(f"æ ·æœ¬æ•°é‡: {data_info['n_samples']}")
        print(f"ç‰¹å¾ç»´åº¦: {data_info['n_features']}")
        print(f"ç›®æ ‡å˜é‡ç»Ÿè®¡: {data_info['target_stats']}")
        
        print("\nğŸ“ ç‰¹å¾èŒƒå›´:")
        for feature, range_info in data_info['feature_ranges'].items():
            if range_info['type'] == 'continuous':
                print(f"  {feature}: {range_info['min']:.2f} - {range_info['max']:.2f}")
            else:
                print(f"  {feature}: {range_info['values']}")
        
        print("\nâœ… æ•°æ®å¤„ç†æ¨¡å—æµ‹è¯•é€šè¿‡ï¼")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")

if __name__ == "__main__":
    main()